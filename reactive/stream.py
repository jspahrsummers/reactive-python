import itertools
import sys
import traceback
from types import TracebackType
from typing import (
    Any,
    AsyncGenerator,
    AsyncIterable,
    AsyncIterator,
    Awaitable,
    Coroutine,
    Generator,
    Generic,
    Iterable,
    List,
    Optional,
    Type,
    TypeVar,
)

from reactive.agentools import GeneratorFinish, afinish, afinish_non_optional

T = TypeVar("T")
U = TypeVar("U")
V = TypeVar("V")
TIn = TypeVar("TIn", contravariant=True)
TOut = TypeVar("TOut", covariant=True)


class StreamGenerator(AsyncGenerator[Iterable[TOut], TIn], Generic[TOut, TIn]):
    """
    Represents an asynchronous generator which yields a stream of values each time it is resumed (represented as an iterable).

    The streams (iterables) are of indefinite length, so they may yield zero or any other number of values. This offers additional flexibility over the base AsyncGenerator interface:

    1. By yielding an empty iterable, the generator is able to indicate that it has nothing to output for the value that was sent to it, and that it wishes to suspend execution until another value is available (useful, e.g., for filtering or accumulation).

    2. By yielding an iterable of more than one value, the generator can expand a single input into multiple outputs, or yield values that were previously accumulated. We prefer to represent this as an iterable (compared to a tuple or list) to support lazy generation, in case the downstream consumer will not actually consume all of the values.

    As a coincidental (but nice) side effect, this also makes it easy to send an "empty value" for the first invocation of asend(), which is required by the AsyncGenerator contract but not captured correctly in `typing`: https://gist.github.com/jspahrsummers/32a8096667cf9f17d5e8fddeb081b202
    """

    def __init__(self, agen: AsyncGenerator[Iterable[TOut], TIn]):
        """
        Wraps a regular asynchronous generator that generates a stream of values.
        """

        self._agen = agen

        if __debug__:
            self._stack_summary = traceback.extract_stack(limit=2)

        super().__init__()

    def __str__(self) -> str:
        if __debug__:
            trace = "\n".join(traceback.format_list(self._stack_summary))
            return f"StreamGenerator created at:\n{trace}"
        else:
            return super().__str__()

    def __aiter__(self) -> "StreamGenerator[TOut, TIn]":
        return self

    async def __anext__(self) -> Iterable[TOut]:
        return await self._agen.__anext__()

    async def asend(self, x: TIn) -> Iterable[TOut]:
        return await self._agen.asend(x)

    async def athrow(
        self,
        exc_type: Type[BaseException],
        exc_value: Optional[BaseException] = None,
        traceback: Optional[TracebackType] = None,
    ) -> Iterable[TOut]:
        return await self._agen.athrow(exc_type, exc_value, traceback)

    async def aclose(self) -> None:
        await self._agen.aclose()

    TOut2 = TypeVar("TOut2", covariant=True)

    def __or__(
        self, other: "StreamGenerator[TOut2, TOut]"
    ) -> "StreamGenerator[TOut2, TIn]":
        """
        Chains together two stream generators with a convenient pipelining syntax:

            composed_stream = input_stream | output_stream
        
        Each value in each stream yielded from the left generator is fed into the right generator, in order. Yields the streams generated by the right generator, in the same order.
        """

        if not isinstance(other, StreamGenerator):
            return NotImplemented

        return flatmap(self, other)

    def __le__(self, upstream: AsyncIterable[TIn]) -> AsyncIterable[TOut]:
        """
        Connects the stream generator to a data source (represented as an asynchronous iterable), so the generator will run over the values it receives.

        This can be used in either direction, as long as the arrow points "into" the stream generator. For example:

            outputs = stream <= inputs
            outputs = inputs >= stream

        Returns each value of each iterable yielded by the generator, in order.
        """

        if not hasattr(upstream, "__aiter__"):
            return NotImplemented

        return connect(self, upstream)


def flatmap(
    gen1: AsyncGenerator[Iterable[U], T], gen2: AsyncGenerator[Iterable[V], U]
) -> StreamGenerator[V, T]:
    """
    Chains together two generators of iterables, such that each value in each iterable yielded from the left generator is fed into the right generator, in order.
    
    Yields the iterables generated by the right generator, in the same order.
    """

    async def _chain(
        u_gen: AsyncGenerator[Iterable[U], T], v_gen: AsyncGenerator[Iterable[V], U]
    ) -> AsyncGenerator[Iterable[V], T]:
        async def u_run(coro: Awaitable[Iterable[U]]) -> Iterable[V]:
            try:
                u_values = await coro
            except (StopAsyncIteration, GeneratorExit) as stop:
                # If v_gen also throws StopAsyncIteration or GeneratorExit here, the exception will propagate and we will gracefully exit.
                return await afinish_non_optional(v_gen, stop)
            except BaseException as err:
                # Delegate error handling to v_gen, so it may decide to suppress the error and turn it into values, or else re-raise to the consumer of flatmap().
                v_values = await v_gen.athrow(type(err), err, err.__traceback__)

                try:
                    # If we're still here, we need v_gen to finish.
                    v_last_values = await afinish_non_optional(v_gen, err)
                except (StopAsyncIteration, GeneratorExit):
                    # A clean exit, with no final values.
                    return v_values
                else:
                    return itertools.chain(v_values, v_last_values)
            else:
                # u_gen still alive.
                v_values = []

                try:
                    # FIXME: Undesirable batching. We should yield v_values incrementally.
                    for u in u_values:
                        v_values += await v_gen.asend(u)
                except (StopAsyncIteration, GeneratorExit):
                    # v_gen completed early, so close u_gen (with no opportunity for final values).
                    await u_gen.aclose()

                # Other exception types are propagated, as real errors.
                return v_values

        try:
            # TODO: Defer this until we actually have work for the generators to do?
            await u_gen.__anext__()
            await v_gen.__anext__()

            v_values: Iterable[V] = []
            while True:
                try:
                    t = yield v_values
                except GeneratorFinish as finish:
                    # Consumer asked us to finish up. Propagate to u_gen.
                    yield await u_run(afinish_non_optional(u_gen, finish))

                    # If we're still here, give v_gen the opportunity too.
                    yield await afinish_non_optional(v_gen, finish)

                    # Jump to finalizing the generators.
                    break
                except GeneratorExit:
                    # Not permitted to yield any values after receiving this, so just exit.
                    break
                except BaseException as err:
                    # Delegate error handling to u_gen.
                    v_values = await u_run(
                        u_gen.athrow(type(err), err, err.__traceback__)
                    )

                    continue

                v_values = await u_run(u_gen.asend(t))
        finally:
            await u_gen.aclose()
            await v_gen.aclose()

    return StreamGenerator(_chain(gen1, gen2))


async def connect(
    gen: AsyncGenerator[Iterable[TOut], TIn], upstream: AsyncIterable[TIn]
) -> AsyncIterable[TOut]:
    """
    Connects a generator of iterables to a data source (represented as an asynchronous iterable), so the generator will run over each of the input values.

    Returns each value of each iterable yielded by the generator, in order.
    """
    await gen.__anext__()

    try:
        async for t in upstream:
            for u in await gen.asend(t):
                yield u

        try:
            for u in await afinish_non_optional(gen):
                yield u
        except GeneratorExit:
            pass
    finally:
        await gen.aclose()
